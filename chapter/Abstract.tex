%\renewcommand{\abstractname}{Kurzfassung}
%\begin{otherlanguage}{english}
\begin{abstract}
The research field of Music Information Retrieval is concerned with the automatic analysis of musical characteristics. One aspect that has not received much attention so far is the automatic analysis of sung lyrics. On the other hand, the field of Automatic Speech Recognition has produced many methods for the automatic analysis of speech, but those have rarely been employed for singing so far. This thesis analyzes the feasibility of applying various speech recognition methods to singing, and suggests adaptations. In addition, the routes to practical applications for these systems are described. Five tasks are considered: Phoneme recognition, language identification, keyword spotting, lyrics-to-audio alignment, and retrieval of lyrics from sung queries.\\
The main bottleneck in almost all of these tasks lies in the recognition of phonemes from sung audio. Conventional models trained on speech do not perform well when applied to singing. Training models on singing is difficult due to a lack of annotated data. This thesis offers two approaches for generating such data sets. For the first one, speech recordings are made more ``song-like''. In the second approach, textual lyrics are automatically aligned to an existing singing data set. In both cases, these new data sets are then used for training new acoustic models, offering significant improvements over models trained on speech.\\
In addition to these improved acoustic models, speech recognition algorithms for individual tasks are evaluated on and adapted to singing. For language identification, an i-vector extraction approach is tested, and a completely new approach based on the calculation of phoneme statistics using the new acoustic models is presented. For keyword spotting, the new acoustic models were integrated into a keyword-filler HMM system. Additionally, duration modeling is applied to the results, exploiting knowledge about durations in singing.\\
In both lyrics-to-singing alignment and retrieval of textual lyrics from sung queries, an alignment between the audio recording and the text lyrics is performed. For retrieval, the scores for all possible lyrics are compared. A first approach employs ``classic'' Viterbi alignment, and is used for the generation of the previously mentioned singing data set. Two new approaches perform alignment between the lyrics' phonemes and phoneme posteriorgrams extracted with the new acoustic models, taking phonetic knowledge into account. One of these approaches performed best in the \textit{MIREX} 2017 lyrics-to-audio alignment challenge. Additionally, a practical application to expletive detection in singing is presented.
\end{abstract}
%\end{otherlanguage}
\begin{otherlanguage}{ngerman}
%\renewcommand{\abstractname}{Kurzfassung}
%\newcommand{\dtabstract}{\hyphenpenalty=10000}
%{\dtabstract
\begin{abstract}
Das Gebiet des Music Information Retrieval befasst sich mit der automatischen Analyse von musikalischen Charakteristika. Ein Aspekt, der bisher kaum erforscht wurde, ist dabei der gesungene Text. Auf der anderen Seite werden in der automatischen Spracherkennung viele Methoden für die automatische Analyse von Sprache entwickelt, jedoch selten für Gesang. Die vorliegende Arbeit untersucht die Anwendung von Methoden aus der Spracherkennung auf Gesang und beschreibt mögliche Anpassungen. Zudem werden Wege zur praktischen Anwendung dieser Ansätze aufgezeigt. Fünf Themen werden dabei betrachtet: Phonemerkennung, Sprachenidentifikation, Schlagwortsuche, Text-zu-Gesangs-Alignment und Suche von Texten anhand von gesungenen Anfragen.\\
Das größte Hindernis bei fast allen dieser Themen ist die Erkennung von Phonemen aus Gesangsaufnahmen. Herkömmliche, auf Sprache trainierte Modelle, bieten keine guten Ergebnisse für Gesang. Das Trainieren von Modellen auf Gesangsdaten ist schwierig, da kaum annotierte Daten verfügbar sind. Diese Arbeit zeigt zwei Ansätze auf, um solche Daten zu generieren. Für den ersten wurden Sprachaufnahmen künstlich ähnlicher zu Gesang gemacht. Für den zweiten wurden Texte automatisch zu einem vorhandenen Gesangsdatensatz alignt. Beide neuen Datensätze wurden dann zum Trainieren neuer akustischer Modelle genutzt und bieten signifikante Verbesserungen gegenüber sprachbasierten Modellen.\\
Zusätzlich zu diesen verbesserten akustischen Modellen wurden Algorithmen der Spracherkennung auf Gesang evaluiert und angepasst. Für die Sprachenidentifikation wird ein Ansatz auf Basis von i-vector-Extraktion getestet und ein völlig neuer vorgestellt, welcher auf der Berechnung von Phonemstatistiken mit Hilfe der neuen akustischen Modelle basiert. Für die Schlagwortsuche wurden die neuen akustischen Modelle in ein Keyword-Filler-HMM-System integriert. Auch Duration Modeling wurde eingesetzt, um Erkenntnisse über die Dauer von Phoneme in Gesang auszunutzen.\\
Im Text-zu-Gesangs-Alignment und in der Textsuche wird jeweils ein Alignment zwischen der Audioaufnahme und den Texten berechnet. Für die Textsuche werden dann die Ergebnisse für alle möglichen Texte verglichen. In einem ersten Versuch wird ``klassisches'' Viterbi-Alignment eingesetzt, u.a. auch zur Erzeugung des erwähnten Datensatzes. In zwei neuen Ansätzen wird das Alignment zwischen den Phonemen des Textes und mit den neuen akustischen Modellen erzeugten Posteriorgrammen berechnet, wobei phonetische Erkenntnisse mit einbezogen werden. Eine dieser Methoden erzielte bei der \textit{MIREX} 2017 Lyrics-to-Audio Alignment Challenge die besten Ergebnisse. Außerdem wird eine praktische Anwendung für die automatische Schimpfwortsuche vorgestellt.
\end{abstract}

\end{otherlanguage}
